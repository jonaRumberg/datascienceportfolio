{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb478d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "df_train = pd.read_csv(\"data/smoker_train.csv\")\n",
    "df_train = df_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1fc58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa811dd5",
   "metadata": {},
   "source": [
    "# Allgemeine Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cfbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1bd95",
   "metadata": {},
   "source": [
    "## Cross Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc545c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_train.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709df04c",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_counts = df_train['smoking'].value_counts()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(smoking_counts, labels=['Non-Smoker', 'Smoker'], autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))\n",
    "plt.title('Class Distribution: Smokers vs Non-Smokers')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38485869",
   "metadata": {},
   "source": [
    "# Machine Learning Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store test error and train error for each model\n",
    "# [model, test_mse, train_mse, test_accuracy, train_accuracy, test_f1, train_f1]\n",
    "model_errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac219e",
   "metadata": {},
   "source": [
    "## Naives Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell, das immer \"Non-Smoker\" (0) vorhersagt\n",
    "y_true = df_train['smoking']\n",
    "y_pred_naive = np.zeros_like(y_true)\n",
    "\n",
    "# Fehlerwerte berechnen\n",
    "accuracy = accuracy_score(y_true, y_pred_naive)\n",
    "f1 = f1_score(y_true, y_pred_naive)\n",
    "mse = mean_squared_error(y_true, y_pred_naive)\n",
    "\n",
    "print(f\"Accuracy (immer Non-Smoker): {accuracy:.4f}\")\n",
    "print(f\"F1-Score (immer Non-Smoker): {f1:.4f}\")\n",
    "print(f\"Mean Squared Error (immer Non-Smoker): {mse:.4f}\")\n",
    "\n",
    "\n",
    "model_errors.append(['Naive Model', mse, mse, accuracy, accuracy, f1, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aff011",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a40ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all columns except 'weight(kg)' and smoking as features\n",
    "X = df_train[['height(cm)', 'waist(cm)', 'age', 'hemoglobin']]\n",
    "y = df_train['weight(kg)']\n",
    "\n",
    "# Split data into training and testing sets (using only training set for comparison)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training der Modelle\n",
    "lr_model = LinearRegression().fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred = lr_model.predict(X_test_1)\n",
    "\n",
    "print(f\"Intercept: {lr_model.intercept_}\")\n",
    "for name, coef in zip(X.columns, lr_model.coef_):\n",
    "    print(f\"Coefficient for {name}: {coef}\")\n",
    "\n",
    "mse = mean_squared_error(y_test_1, y_pred)\n",
    "print(f\"Test Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b1869",
   "metadata": {},
   "source": [
    "## Decision Tree limited leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bdfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[['height(cm)', 'waist(cm)', 'hemoglobin']]\n",
    "y = df_train['smoking']\n",
    "\n",
    "# Split data into training and testing sets (using only training set for comparison)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training der Modelle\n",
    "dtc = DecisionTreeClassifier(random_state=0, max_leaf_nodes=7).fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_train = dtc.predict(X_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy of Decision Tree-Train: ', accuracy_score(y_pred_train, y_train))\n",
    "print('Accuracy of Decision Tree-Test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "model_errors.append(['Decision Tree', 0, 0, accuracy_score(y_pred, y_test), accuracy_score(y_pred_train, y_train), f1_score(y_test, y_pred), f1_score(y_train, y_pred_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00ddb7",
   "metadata": {},
   "source": [
    "## Decision Tree limited depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78711fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input Variablen\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "# Output Variable\n",
    "y = df_train['smoking']\n",
    "\n",
    "# Test und Trainingssplit\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# array100 = list(range(1, 20))\n",
    "# for depth in array100:\n",
    "#     # Decision Tree Classifier\n",
    "#     dtc = DecisionTreeClassifier(random_state=0, max_depth=depth).fit(X_train, y_train)\n",
    "    \n",
    "#     # Modellanwendung\n",
    "#     y_pred_train = dtc.predict(X_train)\n",
    "#     y_pred = dtc.predict(X_test)\n",
    "    \n",
    "#     print(f'Depth: {depth}')\n",
    "#     print('Accuracy of Decision Tree-Train: ', accuracy_score(y_pred_train, y_train))\n",
    "#     print('Accuracy of Decision Tree-Test: ', accuracy_score(y_pred, y_test))\n",
    "    # Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier(random_state=0, max_depth=4).fit(X_train, y_train)\n",
    "\n",
    "# Modellanwendung\n",
    "y_pred_train = dtc.predict(X_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "print('Accuracy of Decision Tree-Train: ', accuracy_score(y_pred_train, y_train))\n",
    "print('Accuracy of Decision Tree-Test: ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "\n",
    "model_errors.append(['Decision Tree (max_depth=4)', 0, 0, accuracy_score(y_pred, y_test), accuracy_score(y_pred_train, y_train), f1_score(y_test, y_pred), f1_score(y_train, y_pred_train)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d573ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input Variablen\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "# Output Variable\n",
    "y = df_train['smoking']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ermittlung aller ccp_alpha-Werte durch den Pruning-Pfad\n",
    "path = dtc.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Verwendung von GridSearchCV zur Bestimmung des besten ccp_alpha-Werts\n",
    "param_grid = {'ccp_alpha': ccp_alphas}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Das beste ccp_alpha ermitteln\n",
    "best_ccp_alpha = grid_search.best_params_['ccp_alpha']\n",
    "print(f\"Bestes ccp_alpha durch Cross-Validation: {best_ccp_alpha}\")\n",
    "\n",
    "# Modell mit dem besten ccp_alpha trainieren\n",
    "best_dtc = DecisionTreeClassifier(random_state=42, ccp_alpha=best_ccp_alpha)\n",
    "best_dtc.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen und Genauigkeit auf den Testdaten\n",
    "y_pred = best_dtc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Genauigkeit des besten Modells auf dem Testdatensatz: {accuracy:.4f}\")\n",
    "print(f\"Genauigkeit des besten Modells auf dem Testdatensatz (f1): {f1:.4f}\")\n",
    "print(f\"Mean Squared Error des besten Modells auf dem Testdatensatz: {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "# Entscheidungsbaum des besten Modells visualisieren\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.show()\n",
    "\n",
    "model_errors.append(['Decision Tree (best ccp_alpha)', 0, 0, accuracy, accuracy_score(y_train, best_dtc.predict(X_train)), f1, f1_score(y_train, best_dtc.predict(X_train))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9329e5",
   "metadata": {},
   "source": [
    "## SVC Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfaacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = SVC(random_state=42)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Genauigkeit des besten Modells auf dem Testdatensatz: {accuracy:.4f}\")\n",
    "print(f\"Genauigkeit des besten Modells auf dem Testdatensatz (f1): {f1:.4f}\")\n",
    "\n",
    "\n",
    "model_errors.append(['SVC', 0, 0, accuracy, accuracy_score(y_train, svc_model.predict(X_train)), f1, f1_score(y_train, svc_model.predict(X_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Genauigkeit des besten Modells auf dem Testdatensatz: {accuracy:.4f}\")\n",
    "print(f\"Genauigkeit des besten Modells auf dem Testdatensatz (f1): {f1:.4f}\")\n",
    "\n",
    "\n",
    "model_errors.append(['Linear SVC', 0, 0, accuracy, accuracy_score(y_train, svc_model.predict(X_train)), f1, f1_score(y_train, svc_model.predict(X_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define features and target variable\n",
    "# X = df_train.drop('smoking', axis=1)\n",
    "# y = df_train['smoking']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# svc=SVC() \n",
    "\n",
    "\n",
    "\n",
    "# # declare parameters for hyperparameter tuning\n",
    "# parameters = [ {'C':[1, 10, 100, 1000], 'kernel':['linear']},\n",
    "#                {'C':[1, 10, 100, 1000], 'kernel':['rbf'], 'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
    "#                {'C':[1, 10, 100, 1000], 'kernel':['poly'], 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05]} \n",
    "#               ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# grid_search = GridSearchCV(estimator = svc,  \n",
    "#                            param_grid = parameters,\n",
    "#                            scoring = 'accuracy',\n",
    "#                            cv = 5,\n",
    "#                            verbose=0)\n",
    "\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = grid_search.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# print(f\"Genauigkeit des besten Modells auf dem Testdatensatz: {accuracy:.4f}\")\n",
    "# print(f\"Genauigkeit des besten Modells auf dem Testdatensatz (f1): {f1:.4f}\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7eef7f",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c225dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test Accuracy', data=model_errors_df, color='blue', label='Test Accuracy')\n",
    "sns.lineplot(x='Model', y='Train Accuracy', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
