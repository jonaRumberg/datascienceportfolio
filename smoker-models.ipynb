{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb478d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38485869",
   "metadata": {},
   "source": [
    "# Machine Learning Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/smoker_train.csv\")\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# store test error and train error for each model\n",
    "# [model, test_mse, train_mse, test_accuracy, train_accuracy, test_f1, train_f1]\n",
    "model_errors = []\n",
    "DTC_model_errors = []\n",
    "RFC_model_errors = []\n",
    "SVM_model_errors = []\n",
    "\n",
    "# Split the data into test and train sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac219e",
   "metadata": {},
   "source": [
    "## Naives Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell, das immer \"Non-Smoker\" (0) vorhersagt\n",
    "y = df_train['smoking']\n",
    "y_pred_naive = np.zeros_like(y)\n",
    "\n",
    "# Fehlerwerte berechnen\n",
    "accuracy = accuracy_score(y, y_pred_naive)\n",
    "f1 = f1_score(y, y_pred_naive)\n",
    "mse = mean_squared_error(y, y_pred_naive)\n",
    "\n",
    "print(f\"Accuracy (immer Non-Smoker): {accuracy:.4f}\")\n",
    "print(f\"F1-Score (immer Non-Smoker): {f1:.4f}\")\n",
    "print(f\"Mean Squared Error (immer Non-Smoker): {mse:.4f}\")\n",
    "\n",
    "# Fehlerwerte f√ºr testset berechnen\n",
    "y_test = df_test['smoking']\n",
    "y_test_pred_naive = np.zeros_like(y_test)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred_naive)\n",
    "f1_test = f1_score(y_test, y_test_pred_naive)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred_naive)\n",
    "\n",
    "print(f\"Test Accuracy (immer Non-Smoker): {accuracy_test:.4f}\")\n",
    "print(f\"Test F1-Score (immer Non-Smoker): {f1_test:.4f}\")\n",
    "print(f\"Test Mean Squared Error (immer Non-Smoker): {mse_test:.4f}\")\n",
    "\n",
    "\n",
    "model_errors.append(['Naive Model', mse_test, mse, accuracy_test, accuracy, f1_test, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aff011",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Not relevant to smoker prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a40ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all columns except 'weight(kg)' and smoking as features\n",
    "X = df_train[['height(cm)', 'waist(cm)', 'age', 'hemoglobin']]\n",
    "y = df_train['weight(kg)']\n",
    "\n",
    "# Split data into training and testing sets (using only training set for comparison)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training der Modelle\n",
    "lr_model = LinearRegression().fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred = lr_model.predict(X_test_1)\n",
    "\n",
    "print(f\"Intercept: {lr_model.intercept_}\")\n",
    "for name, coef in zip(X.columns, lr_model.coef_):\n",
    "    print(f\"Coefficient for {name}: {coef}\")\n",
    "\n",
    "mse = mean_squared_error(y_test_1, y_pred)\n",
    "print(f\"Test Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e89f2",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00ddb7",
   "metadata": {},
   "source": [
    "## Decision Tree limited depth of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78711fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input Variablen\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "\n",
    "# Output Variable\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=0, max_depth=1).fit(X, y)\n",
    "\n",
    "# Modellanwendung\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['Decision Tree max depth of 1', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "DTC_model_errors.append(['Decision Tree max depth of 1', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92b579",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c88bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle\n",
    "dtc = DecisionTreeClassifier(random_state=0).fit(X, y)\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# How many leafs does the tree have?\n",
    "print(f\"Number of leafs in the tree: {dtc.get_n_leaves()}\")\n",
    "\n",
    "# How deep is the tree?\n",
    "print(f\"Depth of the tree: {dtc.get_depth()}\")\n",
    "\n",
    "model_errors.append(['Decision Tree', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "DTC_model_errors.append(['Decision Tree', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b1869",
   "metadata": {},
   "source": [
    "## Decision Tree limited leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle\n",
    "dtc = DecisionTreeClassifier(random_state=0, max_leaf_nodes=7).fit(X, y)\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['Decision Tree limited leaves', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "DTC_model_errors.append(['Decision Tree limited leaves', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entscheidungsbaum des besten Modells visualisieren\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c2869",
   "metadata": {},
   "source": [
    "## Decision Tree limited leaves with cross validation for hyperparameter tuning (max leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bdfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle mit K-Fold Cross-Validation\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    dtc, \n",
    "    param_grid={\n",
    "        'max_leaf_nodes': [2, 5, 8, 9, 10, 11, 12, 17, 20]\n",
    "    }, \n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Training der Modelle mit den besten Parametern\n",
    "dtc = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['Decision Tree cv for max leaf', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "DTC_model_errors.append(['Decision Tree cv for max leaf', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entscheidungsbaum des besten Modells visualisieren\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76808385",
   "metadata": {},
   "source": [
    "## Decision Tree limited leaves with cross validation for hyperparameter tuning (max depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle mit K-Fold Cross-Validation\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    dtc, \n",
    "    param_grid={\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    }, \n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Training der Modelle mit den besten Parametern\n",
    "dtc = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['Decision Tree cv for max depth', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "DTC_model_errors.append(['Decision Tree cv for max depth', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entscheidungsbaum des besten Modells visualisieren\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efebe5",
   "metadata": {},
   "source": [
    "## Decision Tree limited leaves with cross validation for hyperparameter tuning (ccp_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d573ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle mit K-Fold Cross-Validation\n",
    "dtc = DecisionTreeClassifier(random_state=0, max_depth=7).fit(X, y)\n",
    "\n",
    "\n",
    "path = dtc.cost_complexity_pruning_path(X, y)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    dtc, \n",
    "    param_grid={\n",
    "        'ccp_alpha': ccp_alphas\n",
    "    }, \n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    "    \n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Training der Modelle mit den besten Parametern\n",
    "dtc = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['Decision Tree cv for ccp_alpha', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "DTC_model_errors.append(['Decision Tree cv for ccp_alpha', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7240019",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a617eac",
   "metadata": {},
   "source": [
    "## Random forest no tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec872f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell trainieren\n",
    "rfc = RandomForestClassifier(random_state=40)\n",
    "rfc.fit(X, y)\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc.predict(X)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl der genutzten B√§ume\n",
    "print(f\"Number of trees in the forest: {len(rfc.estimators_)}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der B√§ume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste erg√§nzen\n",
    "model_errors.append(['Random Forest', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "RFC_model_errors.append(['Random Forest', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488fe47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/graphviz/backend/execute.py:78\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         proc = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    546\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1950\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1949\u001b[39m         err_msg = os.strerror(errno_num)\n\u001b[32m-> \u001b[39m\u001b[32m1950\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1951\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mExecutableNotFound\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Visualisierung mit graphviz\u001b[39;00m\n\u001b[32m     15\u001b[39m graph = graphviz.Source(dot_data)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrandom_forest_tree\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/graphviz/_tools.py:185\u001b[39m, in \u001b[36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     wanted = \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    178\u001b[39m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated.items())\n\u001b[32m    179\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m will be reduced\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    180\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m positional arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mqualification\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as keyword arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m    182\u001b[39m                   stacklevel=stacklevel,\n\u001b[32m    183\u001b[39m                   category=category)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/graphviz/rendering.py:122\u001b[39m, in \u001b[36mRender.render\u001b[39m\u001b[34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[39m\n\u001b[32m    118\u001b[39m filepath = \u001b[38;5;28mself\u001b[39m.save(filename, directory=directory, skip_existing=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    120\u001b[39m args.append(filepath)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m rendered = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[32m    125\u001b[39m     log.debug(\u001b[33m'\u001b[39m\u001b[33mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m, filepath)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/graphviz/_tools.py:185\u001b[39m, in \u001b[36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     wanted = \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    178\u001b[39m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated.items())\n\u001b[32m    179\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m will be reduced\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    180\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m positional arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mqualification\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as keyword arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m    182\u001b[39m                   stacklevel=stacklevel,\n\u001b[32m    183\u001b[39m                   category=category)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/graphviz/backend/rendering.py:326\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[39m\n\u001b[32m    322\u001b[39m cmd += args\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mwork around pytype false alarm\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m os.fspath(outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/graphviz/backend/execute.py:81\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno == errno.ENOENT:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc.stderr:\n",
      "\u001b[31mExecutableNotFound\u001b[39m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "# Einen einzelnen Baum aus deinem Random Forest ausw√§hlen\n",
    "estimator = rfc_best.estimators_[0]\n",
    "\n",
    "# Exportiere als DOT-Datei und wandle in PNG um\n",
    "dot_data = export_graphviz(\n",
    "    estimator,\n",
    "    out_file=None,\n",
    "    feature_names=X.columns,\n",
    "    class_names=['Nicht-Raucher', 'Raucher'],  # falls zutreffend\n",
    "    rounded=True,\n",
    "    filled=True\n",
    ")\n",
    "\n",
    "# Visualisierung mit graphviz\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"random_forest_tree\", format=\"png\", cleanup=False)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9d25c",
   "metadata": {},
   "source": [
    "## Random Forest cross validation hyperparametertuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Hyperparameter Grid definieren\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# GridSearch mit Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl B√§ume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der B√§ume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste erg√§nzen\n",
    "model_errors.append(['Random Forest cv for n_estimators', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "RFC_model_errors.append(['Random Forest cv for n_estimators', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5acbf8",
   "metadata": {},
   "source": [
    "## Random Forest cross validation hyperparametertuning max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Hyperparameter Grid definieren\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "# GridSearch mit Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl B√§ume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der B√§ume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste erg√§nzen\n",
    "model_errors.append(['Random Forest cv for max_depth', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "RFC_model_errors.append(['Random Forest cv for max_depth', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1209577",
   "metadata": {},
   "source": [
    "## Random Forest cross validation hyperparametertuning max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "rfc = RandomForestClassifier(random_state=0, n_estimators=100, max_depth=20)\n",
    "\n",
    "# Hyperparameter Grid definieren\n",
    "param_grid = {\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# GridSearch mit Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl B√§ume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der B√§ume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste erg√§nzen\n",
    "model_errors.append(['Random Forest cv for max_features', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "RFC_model_errors.append(['Random Forest cv for max_features', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b689d",
   "metadata": {},
   "source": [
    "## Random Forest cross validation hyperparametertuning max min samples leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Parameter Grid f√ºr min_samples_leaf\n",
    "param_grid = {\n",
    "    'min_samples_leaf': [1, 2, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "# GridSearchCV Setup\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit Cross-Validation\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl B√§ume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der B√§ume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste erg√§nzen\n",
    "model_errors.append(['Random Forest cv for min_samples_leaf', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "RFC_model_errors.append(['Random Forest cv for min_samples_leaf', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463161d9",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9329e5",
   "metadata": {},
   "source": [
    "## SVM Modell with cross validation for hyperparameter tuning (C, kernel, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80066d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# SVM-Modell\n",
    "svm = SVC(random_state=0)\n",
    "\n",
    "# Grid mit Parametern ‚Äì einfache Auswahl f√ºr Demo-Zwecke\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Cross-Validation mit 5 Folds\n",
    "grid_search = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "svm_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = svm_best.predict(X)\n",
    "y_pred = svm_best.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Fehlerliste erg√§nzen\n",
    "model_errors.append(['SVM cv for C/kernel/gamma', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "SVM_model_errors.append(['SVM cv for C/kernel/gamma', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e5492",
   "metadata": {},
   "source": [
    "### Output Parameter tuning\n",
    "Best parameters found:  {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "SVM Test Accuracy: 0.7269\n",
    "SVM Train Accuracy: 0.7493\n",
    "SVM Test F1-Score: 0.6024\n",
    "SVM Train F1-Score: 0.6291\n",
    "SVM Test Mean Squared Error: 0.2731\n",
    "SVM Train Mean Squared Error: 0.2507"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11decbc2",
   "metadata": {},
   "source": [
    "## SVM Modell with cross validation for hyperparameter tuning (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b639d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# SVM-Modell\n",
    "svm = SVC(random_state=0, gamma='scale', kernel='rbf')\n",
    "\n",
    "# Grid mit Parametern ‚Äì einfache Auswahl f√ºr Demo-Zwecke\n",
    "param_grid = {\n",
    "    'C': [5, 10, 15, 20],\n",
    "}\n",
    "\n",
    "# Cross-Validation mit 5 Folds\n",
    "grid_search = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "svm_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = svm_best.predict(X)\n",
    "y_pred = svm_best.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Fehlerliste erg√§nzen\n",
    "model_errors.append(['SVM cv for C<20', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "SVM_model_errors.append(['SVM cv for C<20', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054ebde",
   "metadata": {},
   "source": [
    "### Output parameter tuning\n",
    "\n",
    "Best parameters found:  {'C': 20}\n",
    "SVM Test Accuracy: 0.7248\n",
    "SVM Train Accuracy: 0.7519\n",
    "SVM Test F1-Score: 0.6020\n",
    "SVM Train F1-Score: 0.6364\n",
    "SVM Test Mean Squared Error: 0.2752\n",
    "SVM Train Mean Squared Error: 0.2481"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732aad07",
   "metadata": {},
   "source": [
    "## SVM Modell with cross validation for hyperparameter tuning (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e77b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# SVM-Modell\n",
    "svm = SVC(random_state=0, gamma='scale', kernel='rbf')\n",
    "\n",
    "# Grid mit Parametern ‚Äì einfache Auswahl f√ºr Demo-Zwecke\n",
    "param_grid = {\n",
    "    'C': [20, 25, 30],\n",
    "}\n",
    "\n",
    "# Cross-Validation mit 5 Folds\n",
    "grid_search = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "svm_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = svm_best.predict(X)\n",
    "y_pred = svm_best.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Fehlerliste erg√§nzen\n",
    "model_errors.append(['SVM cv for C>20', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "SVM_model_errors.append(['SVM cv for C>20', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d03ad9",
   "metadata": {},
   "source": [
    "## SVM Modell Hyperparamter tuned with limited Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead21ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train[['height(cm)', 'hemoglobin', 'Gtp', 'systolic', 'relaxation', 'fasting blood sugar', 'Cholesterol']]\n",
    "X_test = df_test[['height(cm)', 'hemoglobin', 'Gtp', 'systolic', 'relaxation', 'fasting blood sugar', 'Cholesterol']]\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = SVC(random_state=42, kernel='rbf', C=10, gamma='scale')\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['SVM cv for limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "SVM_model_errors.append(['SVM cv for limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5f7b2",
   "metadata": {},
   "source": [
    "## SVM Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfaacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = SVC(random_state=42)\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['SVM', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "SVM_model_errors.append(['SVM', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73eba52",
   "metadata": {},
   "source": [
    "## SVM Linear Kernel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['SVM Linear', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "SVM_model_errors.append(['SVM Linear', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e71868",
   "metadata": {},
   "source": [
    "## SVM Modell limited columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train[['height(cm)', 'hemoglobin', 'Gtp']]\n",
    "X_test = df_test[['height(cm)', 'hemoglobin', 'Gtp']]\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = SVC(random_state=42)\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['SVM limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "SVM_model_errors.append(['SVM limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b1933",
   "metadata": {},
   "source": [
    "## SVM Linear Kernel Modell limited columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe14bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train[['height(cm)', 'hemoglobin', 'Gtp']]\n",
    "X_test = df_test[['height(cm)', 'hemoglobin', 'Gtp']]\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['SVM Linear Kernel limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "SVM_model_errors.append(['SVM Linear Kernel limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7eef7f",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c225dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test MSE', data=model_errors_df, color='blue', label='Test Accuracy')\n",
    "sns.lineplot(x='Model', y='Train MSE', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test F1', data=model_errors_df, color='blue', label='Test Accuracy')\n",
    "sns.lineplot(x='Model', y='Train F1', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test Accuracy', data=model_errors_df, color='blue', label='Test Accuracy')\n",
    "sns.lineplot(x='Model', y='Train Accuracy', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6d18a",
   "metadata": {},
   "source": [
    "# Unnecessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bffc63f",
   "metadata": {},
   "source": [
    "## SVM Model with set C (C=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6219bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Daten vorbereiten\n",
    "# X = df_train.drop('smoking', axis=1)\n",
    "# X_test = df_test.drop('smoking', axis=1)\n",
    "# y = df_train['smoking']\n",
    "# y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# # Train the SVC model\n",
    "# svc_model = SVC(random_state=0, kernel='rbf', C=15, gamma='scale')\n",
    "# svc_model.fit(X, y)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_train = svc_model.predict(X)\n",
    "# y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# # Metriken\n",
    "# accuracy_train = accuracy_score(y, y_pred_train)\n",
    "# accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# f1_train = f1_score(y, y_pred_train)\n",
    "# f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "# mse_train = mean_squared_error(y, y_pred_train)\n",
    "# mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "# print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "# print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "# print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "# print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "# print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# model_errors.append(['SVM', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b6c33",
   "metadata": {},
   "source": [
    "## SVM Model with set C (C=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Daten vorbereiten\n",
    "# X = df_train.drop('smoking', axis=1)\n",
    "# X_test = df_test.drop('smoking', axis=1)\n",
    "# y = df_train['smoking']\n",
    "# y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# # Train the SVC model\n",
    "# svc_model = SVC(random_state=0, kernel='rbf', C=8, gamma='scale')\n",
    "# svc_model.fit(X, y)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred_train = svc_model.predict(X)\n",
    "# y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# # Metriken\n",
    "# accuracy_train = accuracy_score(y, y_pred_train)\n",
    "# accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# f1_train = f1_score(y, y_pred_train)\n",
    "# f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "# mse_train = mean_squared_error(y, y_pred_train)\n",
    "# mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "# print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "# print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "# print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "# print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "# print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# model_errors.append(['SVM', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a656dad",
   "metadata": {},
   "source": [
    "## SVM Model with too many Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define features and target variable\n",
    "# X = df_train.drop('smoking', axis=1)\n",
    "# y = df_train['smoking']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# svc=SVC() \n",
    "\n",
    "\n",
    "\n",
    "# # declare parameters for hyperparameter tuning\n",
    "# parameters = [ {'C':[1, 10, 100, 1000], 'kernel':['linear']},\n",
    "#                {'C':[1, 10, 100, 1000], 'kernel':['rbf'], 'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
    "#                {'C':[1, 10, 100, 1000], 'kernel':['poly'], 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05]} \n",
    "#               ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# grid_search = GridSearchCV(estimator = svc,  \n",
    "#                            param_grid = parameters,\n",
    "#                            scoring = 'accuracy',\n",
    "#                            cv = 5,\n",
    "#                            verbose=0)\n",
    "\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = grid_search.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# print(f\"Genauigkeit des besten Modells auf dem Testdatensatz: {accuracy:.4f}\")\n",
    "# print(f\"Genauigkeit des besten Modells auf dem Testdatensatz (f1): {f1:.4f}\")\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
