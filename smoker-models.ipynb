{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb478d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38485869",
   "metadata": {},
   "source": [
    "# Machine Learning Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(df):\n",
    "    x = df.drop_duplicates()\n",
    "    x = x[abs(x[\"Cholesterol\"] - x[\"HDL\"] - x[\"LDL\"] - x[\"triglyceride\"] / 5) < 30]\n",
    "    return x \n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/smoker_train.csv\")\n",
    "df = clean_up(df)\n",
    "\n",
    "# store test error and train error for each model\n",
    "# [model, test_mse, train_mse, test_accuracy, train_accuracy, test_f1, train_f1]\n",
    "model_errors = []\n",
    "DTC_model_errors = []\n",
    "RFC_model_errors = []\n",
    "SVM_model_errors = []\n",
    "\n",
    "# Split the data into test and train sets\n",
    "df_train, df_test_all = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_test, df_test_unseen = train_test_split(df_test_all, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset Model Errors\n",
    "model_errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac219e",
   "metadata": {},
   "source": [
    "## Naives Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell, das immer \"Non-Smoker\" (0) vorhersagt\n",
    "y = df_train['smoking']\n",
    "y_pred_naive = np.zeros_like(y)\n",
    "\n",
    "# Fehlerwerte berechnen\n",
    "accuracy = accuracy_score(y, y_pred_naive)\n",
    "f1 = f1_score(y, y_pred_naive)\n",
    "mse = mean_squared_error(y, y_pred_naive)\n",
    "\n",
    "print(f\"Accuracy (immer Non-Smoker): {accuracy:.4f}\")\n",
    "print(f\"F1-Score (immer Non-Smoker): {f1:.4f}\")\n",
    "print(f\"Mean Squared Error (immer Non-Smoker): {mse:.4f}\")\n",
    "\n",
    "# Fehlerwerte für testset berechnen\n",
    "y_test = df_test['smoking']\n",
    "y_test_pred_naive = np.zeros_like(y_test)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred_naive)\n",
    "f1_test = f1_score(y_test, y_test_pred_naive)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred_naive)\n",
    "\n",
    "print(f\"Test Accuracy (immer Non-Smoker): {accuracy_test:.4f}\")\n",
    "print(f\"Test F1-Score (immer Non-Smoker): {f1_test:.4f}\")\n",
    "print(f\"Test Mean Squared Error (immer Non-Smoker): {mse_test:.4f}\")\n",
    "\n",
    "\n",
    "model_errors.append(['Naive Model', mse_test, mse, accuracy_test, accuracy, f1_test, f1])\n",
    "DTC_model_errors.append(['Naive Model', mse_test, mse, accuracy_test, accuracy, f1_test, f1])\n",
    "RFC_model_errors.append(['Naive Model', mse_test, mse, accuracy_test, accuracy, f1_test, f1])\n",
    "SVM_model_errors.append(['Naive Model', mse_test, mse, accuracy_test, accuracy, f1_test, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aff011",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Not relevant to smoker prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a40ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all columns except 'weight(kg)' and smoking as features\n",
    "X = df_train[['height(cm)', 'waist(cm)', 'age', 'hemoglobin']]\n",
    "y = df_train['weight(kg)']\n",
    "\n",
    "# Split data into training and testing sets (using only training set for comparison)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training der Modelle\n",
    "lr_model = LinearRegression().fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred = lr_model.predict(X_test_1)\n",
    "\n",
    "print(f\"Intercept: {lr_model.intercept_}\")\n",
    "for name, coef in zip(X.columns, lr_model.coef_):\n",
    "    print(f\"Coefficient for {name}: {coef}\")\n",
    "\n",
    "mse = mean_squared_error(y_test_1, y_pred)\n",
    "print(f\"Test Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e89f2",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00ddb7",
   "metadata": {},
   "source": [
    "## Decision Tree limited depth of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78711fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input Variablen\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "\n",
    "# Output Variable\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=0, max_depth=1).fit(X, y)\n",
    "\n",
    "# Modellanwendung\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['Decision Tree max depth of 1', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "DTC_model_errors.append(['Decision Tree max depth of 1', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.title(\"Decision Tree Depth=1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92b579",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c88bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle\n",
    "dtc = DecisionTreeClassifier(random_state=0).fit(X, y)\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# How many leafs does the tree have?\n",
    "print(f\"Number of leafs in the tree: {dtc.get_n_leaves()}\")\n",
    "\n",
    "# How deep is the tree?\n",
    "print(f\"Depth of the tree: {dtc.get_depth()}\")\n",
    "\n",
    "DTC_model_errors.append(['Decision Tree', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.title(\"Decision Tree no Limitations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c2869",
   "metadata": {},
   "source": [
    "## Decision Tree limited leaves with cross validation for hyperparameter tuning (max leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bdfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle mit K-Fold Cross-Validation\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    dtc, \n",
    "    param_grid={\n",
    "        'max_leaf_nodes': [2, 5, 8, 9, 10, 11, 12, 17, 20]\n",
    "    }, \n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Training der Modelle mit den besten Parametern\n",
    "dtc = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "DTC_model_errors.append(['Decision Tree cv for max leaf', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entscheidungsbaum des besten Modells visualisieren\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.title(\"Decision Tree limited Leaves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76808385",
   "metadata": {},
   "source": [
    "## Decision Tree limited leaves with cross validation for hyperparameter tuning (max depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle mit K-Fold Cross-Validation\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    dtc, \n",
    "    param_grid={\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    }, \n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Training der Modelle mit den besten Parametern\n",
    "dtc = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "model_errors.append(['Decision Tree cv for max depth', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "DTC_model_errors.append(['Decision Tree cv for max depth', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entscheidungsbaum des besten Modells visualisieren\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.title(\"Decision Tree limited Depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efebe5",
   "metadata": {},
   "source": [
    "## Decision Tree limited leaves with cross validation for hyperparameter tuning (ccp_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d573ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Training der Modelle mit K-Fold Cross-Validation\n",
    "dtc = DecisionTreeClassifier(random_state=0).fit(X, y)\n",
    "\n",
    "\n",
    "path = dtc.cost_complexity_pruning_path(X, y)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    dtc, \n",
    "    param_grid={\n",
    "        'ccp_alpha': ccp_alphas\n",
    "    }, \n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    "    \n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Training der Modelle mit den besten Parametern\n",
    "dtc = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = dtc.predict(X)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Calc error values\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Decision Tree Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Decision Tree Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Decision Tree Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Decision Tree Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "DTC_model_errors.append(['Decision Tree cv for ccp_alpha', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a76e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entscheidungsbaum des besten Modells visualisieren\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, filled=True, feature_names=X.columns, class_names=[\"Non Smoker\", \"Smoker\"])\n",
    "plt.title(\"Decision Tree Cost Complexity Pruning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b548e9bb",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8557ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(DTC_model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test MSE', data=model_errors_df, color='blue', label='Test Accuracy')\n",
    "sns.lineplot(x='Model', y='Train MSE', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison MSE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152befb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(DTC_model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test F1', data=model_errors_df, color='blue', label='Test Accuracy')\n",
    "sns.lineplot(x='Model', y='Train F1', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison F1')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(DTC_model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test Accuracy', data=model_errors_df, color='blue', label='Test Accuracy')\n",
    "sns.lineplot(x='Model', y='Train Accuracy', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f5b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(DTC_model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "\n",
    "# Sortierung nach Test Accuracy (aufsteigend)\n",
    "model_errors_df = model_errors_df.sort_values(by='Test F1', ascending=True)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test Accuracy', data=model_errors_df, color='blue', label='Test Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Train Accuracy', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Test F1', data=model_errors_df, color='purple', label='Test F1', marker='o')\n",
    "sns.lineplot(x='Model', y='Train F1', data=model_errors_df, color='red', label='Train F1', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7240019",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a617eac",
   "metadata": {},
   "source": [
    "## Random forest no tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec872f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell trainieren\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(X, y)\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc.predict(X)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl der genutzten Bäume\n",
    "print(f\"Number of trees in the forest: {len(rfc.estimators_)}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der Bäume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste ergänzen\n",
    "RFC_model_errors.append(['Random Forest', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances\n",
    "feat_importances = pd.Series(rfc.feature_importances_, index=X.columns)\n",
    "feat_importances.sort_values(ascending=True).plot(kind='barh', figsize=(8,6))\n",
    "plt.title(\"Feature Importances im Random Forest Modell\")\n",
    "plt.xlabel(\"Wichtigkeit\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9d25c",
   "metadata": {},
   "source": [
    "## Random Forest cross validation hyperparametertuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Hyperparameter Grid definieren\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300]\n",
    "}\n",
    "\n",
    "# GridSearch mit Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl Bäume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der Bäume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste ergänzen\n",
    "RFC_model_errors.append(['Random Forest cv for n_estimators<300', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ad380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Hyperparameter Grid definieren\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 500, 600, 700, 800]\n",
    "}\n",
    "\n",
    "# GridSearch mit Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl Bäume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der Bäume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste ergänzen\n",
    "RFC_model_errors.append(['Random Forest cv for n_estimators>300', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5acbf8",
   "metadata": {},
   "source": [
    "## Random Forest cross validation hyperparametertuning max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "rfc = RandomForestClassifier(random_state=0, n_estimators=700)\n",
    "\n",
    "# Hyperparameter Grid definieren\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "# GridSearch mit Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl Bäume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der Bäume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste ergänzen\n",
    "RFC_model_errors.append(['Random Forest cv for max_depth', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1209577",
   "metadata": {},
   "source": [
    "## Random Forest cross validation hyperparametertuning max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "rfc = RandomForestClassifier(random_state=0, n_estimators=700, max_depth=40)\n",
    "\n",
    "# Hyperparameter Grid definieren\n",
    "param_grid = {\n",
    "    'max_features': ['sqrt', 3, 5, 10]\n",
    "}\n",
    "\n",
    "# GridSearch mit Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl Bäume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der Bäume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste ergänzen\n",
    "RFC_model_errors.append(['Random Forest cv for max_features', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b689d",
   "metadata": {},
   "source": [
    "## Random Forest cross validation hyperparametertuning min samples leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell definieren\n",
    "rfc = RandomForestClassifier(random_state=0, n_estimators=700, max_depth=40, max_features='sqrt')\n",
    "\n",
    "\n",
    "# Parameter Grid für min_samples_leaf\n",
    "param_grid = {\n",
    "    'min_samples_leaf': [1, 2, 5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "# GridSearchCV Setup\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit Cross-Validation\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Bestes Modell verwenden\n",
    "rfc_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc_best.predict(X)\n",
    "y_pred = rfc_best.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Anzahl Bäume im besten Modell\n",
    "print(f\"Number of trees in the best model: {rfc_best.n_estimators}\")\n",
    "\n",
    "# Durchschnittliche Tiefe der Bäume ausgeben\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rfc_best.estimators_]\n",
    "avg_depth = sum(tree_depths) / len(tree_depths)\n",
    "print(f\"Average depth of the trees: {avg_depth:.2f}\")\n",
    "\n",
    "# Modellfehlerliste ergänzen\n",
    "model_errors.append(['Random Forest cv for min_samples_leaf', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "RFC_model_errors.append(['Random Forest cv for min_samples_leaf', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances\n",
    "feat_importances = pd.Series(rfc_best.feature_importances_, index=X.columns)\n",
    "feat_importances.sort_values(ascending=True).plot(kind='barh', figsize=(8,6))\n",
    "plt.title(\"Feature Importances im Random Forest Modell\")\n",
    "plt.xlabel(\"Wichtigkeit\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a645c746",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(RFC_model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "\n",
    "# Sortierung nach Test Accuracy (aufsteigend)\n",
    "model_errors_df = model_errors_df.sort_values(by='Test F1', ascending=True)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test Accuracy', data=model_errors_df, color='blue', label='Test Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Train Accuracy', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Test F1', data=model_errors_df, color='purple', label='Test F1', marker='o')\n",
    "sns.lineplot(x='Model', y='Train F1', data=model_errors_df, color='red', label='Train F1', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614c6c0",
   "metadata": {},
   "source": [
    "## Testing Model on unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8fc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test_unseen.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test_unseen['smoking']\n",
    "\n",
    "# Random Forest Modell trainieren\n",
    "rfc = RandomForestClassifier(random_state=0, n_estimators=700, max_depth=40, max_features='sqrt', min_samples_leaf=1)\n",
    "rfc.fit(X, y)\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "y_pred_train = rfc.predict(X)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Random Forest Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"Random Forest Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"Random Forest Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"Random Forest Train Mean Squared Error: {mse_train:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc7c9b",
   "metadata": {},
   "source": [
    "## Model for Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# Random Forest Modell trainieren\n",
    "rfc = RandomForestClassifier(random_state=0, n_estimators=700, max_depth=40, max_features='sqrt', min_samples_leaf=1)\n",
    "rfc.fit(X, y)\n",
    "\n",
    "# Speichern des trainierten Random Forest Modells\n",
    "joblib.dump(rfc, 'smoker_rfc_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463161d9",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9329e5",
   "metadata": {},
   "source": [
    "## SVM Modell with cross validation for hyperparameter tuning (C, kernel, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80066d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# SVM-Modell\n",
    "svm = SVC(random_state=0)\n",
    "\n",
    "# Grid mit Parametern – einfache Auswahl für Demo-Zwecke\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Cross-Validation mit 5 Folds\n",
    "grid_search = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "svm_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = svm_best.predict(X)\n",
    "y_pred = svm_best.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Fehlerliste ergänzen\n",
    "SVM_model_errors.append(['SVM cv for C/kernel/gamma', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e5492",
   "metadata": {},
   "source": [
    "### Output Parameter tuning\n",
    "Best parameters found:  {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "SVM Test Accuracy: 0.7242\n",
    "SVM Train Accuracy: 0.7493\n",
    "SVM Test F1-Score: 0.6034\n",
    "SVM Train F1-Score: 0.6291\n",
    "SVM Test Mean Squared Error: 0.2758\n",
    "SVM Train Mean Squared Error: 0.2507"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11decbc2",
   "metadata": {},
   "source": [
    "## SVM Modell with cross validation for hyperparameter tuning (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b639d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# SVM-Modell\n",
    "svm = SVC(random_state=0, gamma='scale', kernel='rbf')\n",
    "\n",
    "# Grid mit Parametern – einfache Auswahl für Demo-Zwecke\n",
    "param_grid = {\n",
    "    'C': [5, 10, 15, 20],\n",
    "}\n",
    "\n",
    "# Cross-Validation mit 5 Folds\n",
    "grid_search = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "svm_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = svm_best.predict(X)\n",
    "y_pred = svm_best.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Fehlerliste ergänzen\n",
    "SVM_model_errors.append(['SVM cv for C<20', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054ebde",
   "metadata": {},
   "source": [
    "### Output parameter tuning\n",
    "Best parameters found:  {'C': 20}\n",
    "SVM Test Accuracy: 0.7227\n",
    "SVM Train Accuracy: 0.7519\n",
    "SVM Test F1-Score: 0.6041\n",
    "SVM Train F1-Score: 0.6364\n",
    "SVM Test Mean Squared Error: 0.2773\n",
    "SVM Train Mean Squared Error: 0.2481"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732aad07",
   "metadata": {},
   "source": [
    "## SVM Modell with cross validation for hyperparameter tuning (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e77b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "# SVM-Modell\n",
    "svm = SVC(random_state=0, gamma='scale', kernel='rbf')\n",
    "\n",
    "# Grid mit Parametern – einfache Auswahl für Demo-Zwecke\n",
    "param_grid = {\n",
    "    'C': [20, 25, 30],\n",
    "}\n",
    "\n",
    "# Cross-Validation mit 5 Folds\n",
    "grid_search = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training mit CV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "svm_best = grid_search.best_estimator_\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = svm_best.predict(X)\n",
    "y_pred = svm_best.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "# Fehlerliste ergänzen\n",
    "SVM_model_errors.append(['SVM cv for C>20', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n",
    "model_errors.append(['SVM cv for C>20', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d03ad9",
   "metadata": {},
   "source": [
    "## SVM Modell Hyperparamter tuned with limited Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead21ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train[['height(cm)', 'hemoglobin', 'Gtp', 'systolic', 'relaxation', 'fasting blood sugar', 'Cholesterol']]\n",
    "X_test = df_test[['height(cm)', 'hemoglobin', 'Gtp', 'systolic', 'relaxation', 'fasting blood sugar', 'Cholesterol']]\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = SVC(random_state=42, kernel='rbf', C=10, gamma='scale')\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "SVM_model_errors.append(['SVM best Parameter limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5f7b2",
   "metadata": {},
   "source": [
    "## SVM Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfaacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = SVC(random_state=42)\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "SVM_model_errors.append(['SVM', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73eba52",
   "metadata": {},
   "source": [
    "## SVM Linear Kernel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train.drop('smoking', axis=1)\n",
    "X_test = df_test.drop('smoking', axis=1)\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "SVM_model_errors.append(['SVM Linear', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e71868",
   "metadata": {},
   "source": [
    "## SVM Modell limited columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train[['height(cm)', 'hemoglobin', 'Gtp']]\n",
    "X_test = df_test[['height(cm)', 'hemoglobin', 'Gtp']]\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = SVC(random_state=42)\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "SVM_model_errors.append(['SVM limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b1933",
   "metadata": {},
   "source": [
    "## SVM Linear Kernel Modell limited columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe14bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vorbereiten\n",
    "X = df_train[['height(cm)', 'hemoglobin', 'Gtp']]\n",
    "X_test = df_test[['height(cm)', 'hemoglobin', 'Gtp']]\n",
    "y = df_train['smoking']\n",
    "y_test = df_test['smoking']\n",
    "\n",
    "\n",
    "# Train the SVC model\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "svc_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = svc_model.predict(X)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Metriken\n",
    "accuracy_train = accuracy_score(y, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"SVM Train Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"SVM Test F1-Score: {f1_test:.4f}\")\n",
    "print(f\"SVM Train F1-Score: {f1_train:.4f}\")\n",
    "print(f\"SVM Test Mean Squared Error: {mse_test:.4f}\")\n",
    "print(f\"SVM Train Mean Squared Error: {mse_train:.4f}\")\n",
    "\n",
    "SVM_model_errors.append(['SVM Linear Kernel limited Columns', mse_test, mse_train, accuracy_test, accuracy_train, f1_test, f1_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ee190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(SVM_model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "\n",
    "# Sortierung nach Test Accuracy (aufsteigend)\n",
    "model_errors_df = model_errors_df.sort_values(by='Test F1', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test Accuracy', data=model_errors_df, color='blue', label='Test Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Train Accuracy', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Test F1', data=model_errors_df, color='purple', label='Test F1', marker='o')\n",
    "sns.lineplot(x='Model', y='Train F1', data=model_errors_df, color='red', label='Train F1', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7eef7f",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c225dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "# Sortierung nach Test MSE (absteigend)\n",
    "model_errors_df = model_errors_df.sort_values(by='Test MSE', ascending=False)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test MSE', data=model_errors_df, color='blue', label='Test MSE', marker='o')\n",
    "sns.lineplot(x='Model', y='Train MSE', data=model_errors_df, color='orange', label='Train MSE', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "# Sortierung nach Test F1 (aufsteigend)\n",
    "model_errors_df = model_errors_df.sort_values(by='Test Accuracy', ascending=True)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test F1', data=model_errors_df, color='blue', label='Test F1', marker='o')\n",
    "sns.lineplot(x='Model', y='Train F1', data=model_errors_df, color='orange', label='Train F1', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ddf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "# Sortierung nach Test Accuracy (aufsteigend)\n",
    "model_errors_df = model_errors_df.sort_values(by='Test Accuracy', ascending=True)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test Accuracy', data=model_errors_df, color='blue', label='Test Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Train Accuracy', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model errors\n",
    "model_errors_df = pd.DataFrame(model_errors, columns=['Model', 'Test MSE', 'Train MSE', 'Test Accuracy', 'Train Accuracy', 'Test F1', 'Train F1'])\n",
    "\n",
    "# Sortierung nach Test Accuracy (aufsteigend)\n",
    "model_errors_df = model_errors_df.sort_values(by='Test F1', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Model', y='Test Accuracy', data=model_errors_df, color='blue', label='Test Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Train Accuracy', data=model_errors_df, color='orange', label='Train Accuracy', marker='o')\n",
    "sns.lineplot(x='Model', y='Test F1', data=model_errors_df, color='purple', label='Test F1', marker='o')\n",
    "sns.lineplot(x='Model', y='Train F1', data=model_errors_df, color='red', label='Train F1', marker='o')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
